{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamAnderB/Bramlett_DSPN_S24/blob/main/Copy_of_mixed_effects_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2W919d2ZXp7"
      },
      "source": [
        "# Exercise 10: Mixed effects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4nOzVhyZXqK"
      },
      "source": [
        "This homework assignment is designed to give you practice fitting and interpreting mixed effects models.\n",
        "\n",
        "We will be using the **LexicalData.csv** and **Items.csv** files from the *Homework/lexDat* folder in the class GitHub repository again.\n",
        "\n",
        "This data is a subset of the [English Lexicon Project database](https://elexicon.wustl.edu/). It provides the reaction times (in milliseconds) of many subjects as they are presented with letter strings and asked to decide, as quickly and as accurately as possible, whether the letter string is a word or not. The **Items.csv** provides characteristics of the words used, namely frequency (how common is this word?) and length (how many letters?). Unlike in the previous homework, there isn't any missing data in the **LexicalData.csv** file.\n",
        "\n",
        "*Data courtesy of Balota, D.A., Yap, M.J., Cortese, M.J., Hutchison, K.A., Kessler, B., Loftis, B., Neely, J.H., Nelson, D.L., Simpson, G.B., & Treiman, R. (2007). The English Lexicon Project. Behavior Research Methods, 39, 445-459.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DsyBTB6ZXqN"
      },
      "source": [
        "---\n",
        "## 1. Loading and formatting the data (1 point)\n",
        "\n",
        "Load in data from the **LexicalData.csv** and **Items.csv** files. As in the previous homeworks, remove the commas from the reaction times and convert them from strings to numbers. Use `left_join` to add word characteristics `Length` and `Log_Freq_Hal` from **Items** to **LexicalData**.\n",
        "\n",
        "*Note: the `Freq_HAL` variable in **Items.csv** has a similar formatting issue, using string values with commas. We're not going to worry about fixing this since we're only using `Log_Freq_HAL`, which is the natural log transformation of `Freq_HAL`, in this homework.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnBVazYfZXqP",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "url <- \"https://raw.githubusercontent.com/CoAxLab/DataSciencePsychNeuro/master/Homework%20datasets/lexDat/Items.csv\"\n",
        "file <- \"Items.csv\"\n",
        "download.file(url, file)\n",
        "items<-read.csv(\"Items.csv\")\n",
        "\n",
        "url <- \"https://raw.githubusercontent.com/CoAxLab/DataSciencePsychNeuro/master/Homework%20datasets/lexDat/LexicalData.csv\"\n",
        "file <- \"LexicalData.csv\"\n",
        "download.file(url, file)\n",
        "lexical<-read.csv(\"LexicalData.csv\")\n",
        "library(tidyverse)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lexical_items <- left_join(lexical, items, by = c(\"D_Word\" = \"Word\"))\n",
        "lexical_items<-lexical_items%>%\n",
        "  drop_na()%>%\n",
        "  mutate(D_RT= str_replace_all(D_RT, \",\", \"\"))%>%\n",
        "  mutate(D_RT=as.numeric(D_RT))\n",
        "head(lexical_items)"
      ],
      "metadata": {
        "id": "82OaDqx-SK5z",
        "outputId": "bc53011a-86af-4da2-dd12-ea7049677b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 11</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Sub_ID</th><th scope=col>Trial</th><th scope=col>Type</th><th scope=col>D_RT</th><th scope=col>D_Word</th><th scope=col>Outlier</th><th scope=col>D_Zscore</th><th scope=col>Occurrences</th><th scope=col>Length</th><th scope=col>Freq_HAL</th><th scope=col>Log_Freq_HAL</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>157</td><td>1</td><td>1</td><td> 710</td><td>browse     </td><td>false</td><td>-0.437</td><td>2</td><td> 6</td><td>7,016</td><td>8.856</td></tr>\n",
              "\t<tr><th scope=row>2</th><td> 67</td><td>1</td><td>1</td><td>1094</td><td>refrigerant</td><td>false</td><td> 0.825</td><td>3</td><td>11</td><td>104  </td><td>4.644</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>120</td><td>1</td><td>1</td><td> 587</td><td>gaining    </td><td>false</td><td>-0.645</td><td>4</td><td> 7</td><td>4,039</td><td>8.304</td></tr>\n",
              "\t<tr><th scope=row>4</th><td> 21</td><td>1</td><td>1</td><td> 984</td><td>cheerless  </td><td>false</td><td> 0.025</td><td>4</td><td> 9</td><td>14   </td><td>2.639</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>236</td><td>1</td><td>1</td><td> 577</td><td>pattered   </td><td>false</td><td>-0.763</td><td>4</td><td> 8</td><td>4    </td><td>1.386</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>236</td><td>2</td><td>1</td><td> 715</td><td>conjures   </td><td>false</td><td>-0.364</td><td>4</td><td> 8</td><td>194  </td><td>5.268</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 11\n\n| <!--/--> | Sub_ID &lt;int&gt; | Trial &lt;int&gt; | Type &lt;int&gt; | D_RT &lt;dbl&gt; | D_Word &lt;chr&gt; | Outlier &lt;chr&gt; | D_Zscore &lt;dbl&gt; | Occurrences &lt;int&gt; | Length &lt;int&gt; | Freq_HAL &lt;chr&gt; | Log_Freq_HAL &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 157 | 1 | 1 |  710 | browse      | false | -0.437 | 2 |  6 | 7,016 | 8.856 |\n| 2 |  67 | 1 | 1 | 1094 | refrigerant | false |  0.825 | 3 | 11 | 104   | 4.644 |\n| 3 | 120 | 1 | 1 |  587 | gaining     | false | -0.645 | 4 |  7 | 4,039 | 8.304 |\n| 4 |  21 | 1 | 1 |  984 | cheerless   | false |  0.025 | 4 |  9 | 14    | 2.639 |\n| 5 | 236 | 1 | 1 |  577 | pattered    | false | -0.763 | 4 |  8 | 4     | 1.386 |\n| 6 | 236 | 2 | 1 |  715 | conjures    | false | -0.364 | 4 |  8 | 194   | 5.268 |\n\n",
            "text/latex": "A data.frame: 6 × 11\n\\begin{tabular}{r|lllllllllll}\n  & Sub\\_ID & Trial & Type & D\\_RT & D\\_Word & Outlier & D\\_Zscore & Occurrences & Length & Freq\\_HAL & Log\\_Freq\\_HAL\\\\\n  & <int> & <int> & <int> & <dbl> & <chr> & <chr> & <dbl> & <int> & <int> & <chr> & <dbl>\\\\\n\\hline\n\t1 & 157 & 1 & 1 &  710 & browse      & false & -0.437 & 2 &  6 & 7,016 & 8.856\\\\\n\t2 &  67 & 1 & 1 & 1094 & refrigerant & false &  0.825 & 3 & 11 & 104   & 4.644\\\\\n\t3 & 120 & 1 & 1 &  587 & gaining     & false & -0.645 & 4 &  7 & 4,039 & 8.304\\\\\n\t4 &  21 & 1 & 1 &  984 & cheerless   & false &  0.025 & 4 &  9 & 14    & 2.639\\\\\n\t5 & 236 & 1 & 1 &  577 & pattered    & false & -0.763 & 4 &  8 & 4     & 1.386\\\\\n\t6 & 236 & 2 & 1 &  715 & conjures    & false & -0.364 & 4 &  8 & 194   & 5.268\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  Sub_ID Trial Type D_RT D_Word      Outlier D_Zscore Occurrences Length\n",
              "1 157    1     1     710 browse      false   -0.437   2            6    \n",
              "2  67    1     1    1094 refrigerant false    0.825   3           11    \n",
              "3 120    1     1     587 gaining     false   -0.645   4            7    \n",
              "4  21    1     1     984 cheerless   false    0.025   4            9    \n",
              "5 236    1     1     577 pattered    false   -0.763   4            8    \n",
              "6 236    2     1     715 conjures    false   -0.364   4            8    \n",
              "  Freq_HAL Log_Freq_HAL\n",
              "1 7,016    8.856       \n",
              "2 104      4.644       \n",
              "3 4,039    8.304       \n",
              "4 14       2.639       \n",
              "5 4        1.386       \n",
              "6 194      5.268       "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXy81Viishk1"
      },
      "source": [
        "---\n",
        "## 2. Model fitting (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7_gEgkbzFtU"
      },
      "source": [
        "First, fit a linear model with `Log_Freq_HAL` and `Length` as predictors, and `D_RT` as the output. Include an interaction term. Use `summary()` to look at the model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIOIg-GRz4rN",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "8bdbcfa9-c4fb-4375-d171-12942746c89f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = D_RT ~ Log_Freq_HAL * Length, data = lexical_items)\n",
              "\n",
              "Residuals:\n",
              "     Min       1Q   Median       3Q      Max \n",
              "-1118.01  -205.23   -86.95    90.77  3147.07 \n",
              "\n",
              "Coefficients:\n",
              "                    Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)         610.1903    14.6678  41.601  < 2e-16 ***\n",
              "Log_Freq_HAL         -6.0239     1.9678  -3.061  0.00221 ** \n",
              "Length               47.7531     1.6368  29.175  < 2e-16 ***\n",
              "Log_Freq_HAL:Length  -2.9421     0.2348 -12.528  < 2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 359.1 on 62606 degrees of freedom\n",
              "Multiple R-squared:  0.09473,\tAdjusted R-squared:  0.09469 \n",
              "F-statistic:  2184 on 3 and 62606 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "simp_m<-lm(D_RT~Log_Freq_HAL*Length,data=lexical_items)\n",
        "summary(simp_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbeg_JrS3mwU"
      },
      "source": [
        "Now, install `lme4` using `install.packages()` and then load the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFSnvvb_re2O",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "035c2dfa-f127-4ec4-b258-92596df153cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘minqa’, ‘nloptr’, ‘Rcpp’, ‘RcppEigen’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘numDeriv’\n",
            "\n",
            "\n",
            "Loading required package: Matrix\n",
            "\n",
            "\n",
            "Attaching package: ‘Matrix’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:tidyr’:\n",
            "\n",
            "    expand, pack, unpack\n",
            "\n",
            "\n",
            "\n",
            "Attaching package: ‘lmerTest’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:lme4’:\n",
            "\n",
            "    lmer\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:stats’:\n",
            "\n",
            "    step\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "#install.packages(\"lme4\")\n",
        "#install.packages(\"lmerTest\")\n",
        "library(lme4)\n",
        "library(lmerTest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZJns7xr41nW"
      },
      "source": [
        "Now fit a mixed effects model that includes the same predictors as the linear model above, as well as random intercepts for `Sub_ID` (i.e., cases where subject ID shifts the RT mean). Use `summary()` to look at the model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kjwT0je57N7",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "0e6dde7a-6cbc-4c19-d996-c66d54decde0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n",
              "lmerModLmerTest]\n",
              "Formula: D_RT ~ Log_Freq_HAL * Length + (1 | Sub_ID)\n",
              "   Data: lexical_items\n",
              "\n",
              "REML criterion at convergence: 888235.6\n",
              "\n",
              "Scaled residuals: \n",
              "    Min      1Q  Median      3Q     Max \n",
              "-4.5058 -0.5472 -0.1568  0.3103 10.7381 \n",
              "\n",
              "Random effects:\n",
              " Groups   Name        Variance Std.Dev.\n",
              " Sub_ID   (Intercept) 46333    215.3   \n",
              " Residual             82978    288.1   \n",
              "Number of obs: 62610, groups:  Sub_ID, 299\n",
              "\n",
              "Fixed effects:\n",
              "                      Estimate Std. Error         df t value Pr(>|t|)    \n",
              "(Intercept)           616.8445    17.1522  1051.7517  35.963  < 2e-16 ***\n",
              "Log_Freq_HAL           -7.4374     1.5830 62314.1248  -4.698 2.63e-06 ***\n",
              "Length                 47.7477     1.3162 62313.3658  36.277  < 2e-16 ***\n",
              "Log_Freq_HAL:Length    -2.8778     0.1888 62313.3660 -15.239  < 2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Correlation of Fixed Effects:\n",
              "            (Intr) Lg_F_HAL Length\n",
              "Log_Frq_HAL -0.645                \n",
              "Length      -0.656  0.917         \n",
              "Lg_Fr_HAL:L  0.582 -0.942   -0.923"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "mem_m<-lmer(D_RT~Log_Freq_HAL*Length+(1|Sub_ID),data=lexical_items)\n",
        "summary(mem_m)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfb_ovk7JFGt"
      },
      "source": [
        "---\n",
        "## 3. Model assessment (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7B1Ux6RHGjy"
      },
      "source": [
        "Compare the three t-values for the fixed effects and the mixed effects models. How do they differ, and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCi5gYOeHo6m"
      },
      "source": [
        "> *Write your response here*\n",
        "\n",
        "listed here:\n",
        "Log_Freq_HAL -3.061 --- -4.698\n",
        "Length  29.175 ---   36.277\n",
        "Log_Freq_HAL -12.528  ---  -15.239.\n",
        "\n",
        "the mixed effect model has higher t values (aka further from 0).  That is the higher t-values indicate a greater distance from the null hypothesis value. the Mixed effect model finds a strong effect. This is happening because the randomness is being accounted for in the random differences in performance between participants individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hukKG1AbGqXM"
      },
      "source": [
        "Use the Aikeke Information Criterion (AIC) to compare these two models.\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "Which one is better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMDg8qb5FhJz",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "a0243ed5-2cb1-4cfd-bb0c-7564cef3470c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "914436.394428578"
            ],
            "text/markdown": "914436.394428578",
            "text/latex": "914436.394428578",
            "text/plain": [
              "[1] 914436.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "888247.571057001"
            ],
            "text/markdown": "888247.571057001",
            "text/latex": "888247.571057001",
            "text/plain": [
              "[1] 888247.6"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "AIC(simp_m)\n",
        "AIC(mem_m)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4oTfsYmIvYt"
      },
      "source": [
        "> *Write your response here*\n",
        "> The mixed effect model is better because although it is more complex it has a lower AIC(which builds in a penalty for complexity). The lower AIC indicates that how well models explain for the variance in the data set considering complexity of the model with a preference for simpler models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARF2PF2yLXkZ"
      },
      "source": [
        "---\n",
        "##  4. Reflection (1 point)\n",
        "\n",
        "What other random effects could be controlled for in this data set?\n",
        "\n",
        "> *Write your response here*\n",
        "> The trial number could also be a random effect. We would expect that as trial number gets larger some variation may occur do to either getting better at the task or because of exhaustion. If we use it as a random effect, our main effects are more interpretabile because we don't need to consider the change over the task as much."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4MPECMmZXqe"
      },
      "source": [
        "**DUE:** 5pm EST, March 18, 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9GUofXN4BVy"
      },
      "source": [
        "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here.\n",
        "> *Someone's Name*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}